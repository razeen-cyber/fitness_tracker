{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Dataset\n",
    "\n",
    "In this file we will be doing the following\n",
    "\n",
    "* Creating the dataset from raw data\n",
    "* Merging the dataset (Containing measurements from accelerometer and gyroscope)\n",
    "* Preprocessing the data\n",
    "* Cleaning the data\n",
    "* Finally exporting the preprocessed data and storing it in `'../data/interim'` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary library\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the data\n",
    "files = glob('../data/raw/MetaMotion/*.csv')\n",
    "data_path = '../data/raw/MetaMotion/'\n",
    "\n",
    "def read_data(files):\n",
    "    accel_df = pd.DataFrame()\n",
    "    gyro_df = pd.DataFrame()\n",
    "\n",
    "# Adding exercise sets for each type of dataset\n",
    "    accel_set = 1\n",
    "    gyro_set  = 1\n",
    "\n",
    "    for f in files:\n",
    "        participant = f.split('-')[0].replace(data_path, '')\n",
    "        # Label - Type of exercise e.g ohp - Overhead press\n",
    "        label = f.split('-')[1]\n",
    "        # Quick fixing category for other files\n",
    "        category = f.split('-')[2].rstrip('123').rstrip('_MetaWear_2019')\n",
    "        df = pd.read_csv(f)\n",
    "        df['participant'] = participant\n",
    "        df['label'] = label\n",
    "        df['category'] = category\n",
    "\n",
    "        if 'Accelerometer' in f:\n",
    "            df['set'] = accel_set\n",
    "            accel_set += 1\n",
    "            accel_df = pd.concat([accel_df, df])\n",
    "\n",
    "        if 'Gyroscope' in f:\n",
    "            df['set'] = gyro_set\n",
    "            gyro_set += 1\n",
    "            gyro_df = pd.concat([gyro_df, df])\n",
    "    \n",
    "    accel_df.index = pd.to_datetime(accel_df['epoch (ms)'], unit='ms')\n",
    "    gyro_df.index = pd.to_datetime(gyro_df['epoch (ms)'], unit='ms') \n",
    "    del accel_df['epoch (ms)']\n",
    "    del accel_df['time (01:00)']\n",
    "    del accel_df['elapsed (s)']\n",
    "\n",
    "    del gyro_df['epoch (ms)']\n",
    "    del gyro_df['time (01:00)']\n",
    "    del gyro_df['elapsed (s)'] \n",
    "\n",
    "    return accel_df, gyro_df\n",
    "\n",
    "accel_df, gyro_df = read_data(files) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the data (Accelerometer and Gyroscope)\n",
    "\n",
    "merged_data = pd.concat([accel_df.iloc[:,:3], gyro_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-axis (g)</th>\n",
       "      <th>y-axis (g)</th>\n",
       "      <th>z-axis (g)</th>\n",
       "      <th>x-axis (deg/s)</th>\n",
       "      <th>y-axis (deg/s)</th>\n",
       "      <th>z-axis (deg/s)</th>\n",
       "      <th>participant</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.382</th>\n",
       "      <td>-0.060</td>\n",
       "      <td>-1.021</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.462</th>\n",
       "      <td>-0.035</td>\n",
       "      <td>-1.037</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.542</th>\n",
       "      <td>-0.045</td>\n",
       "      <td>-1.029</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.622</th>\n",
       "      <td>-0.039</td>\n",
       "      <td>-1.027</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.702</th>\n",
       "      <td>-0.049</td>\n",
       "      <td>-1.031</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         x-axis (g)  y-axis (g)  z-axis (g)  x-axis (deg/s)  \\\n",
       "epoch (ms)                                                                    \n",
       "2019-01-20 17:35:13.382      -0.060      -1.021      -0.058             NaN   \n",
       "2019-01-20 17:35:13.462      -0.035      -1.037      -0.026             NaN   \n",
       "2019-01-20 17:35:13.542      -0.045      -1.029      -0.033             NaN   \n",
       "2019-01-20 17:35:13.622      -0.039      -1.027      -0.039             NaN   \n",
       "2019-01-20 17:35:13.702      -0.049      -1.031      -0.049             NaN   \n",
       "\n",
       "                         y-axis (deg/s)  z-axis (deg/s) participant label  \\\n",
       "epoch (ms)                                                                  \n",
       "2019-01-20 17:35:13.382             NaN             NaN         NaN   NaN   \n",
       "2019-01-20 17:35:13.462             NaN             NaN         NaN   NaN   \n",
       "2019-01-20 17:35:13.542             NaN             NaN         NaN   NaN   \n",
       "2019-01-20 17:35:13.622             NaN             NaN         NaN   NaN   \n",
       "2019-01-20 17:35:13.702             NaN             NaN         NaN   NaN   \n",
       "\n",
       "                        category  set  \n",
       "epoch (ms)                             \n",
       "2019-01-20 17:35:13.382      NaN  NaN  \n",
       "2019-01-20 17:35:13.462      NaN  NaN  \n",
       "2019-01-20 17:35:13.542      NaN  NaN  \n",
       "2019-01-20 17:35:13.622      NaN  NaN  \n",
       "2019-01-20 17:35:13.702      NaN  NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "\n",
    "merged_data.columns = [\n",
    "    'acc_x',\n",
    "    'acc_y',\n",
    "    'acc_z',\n",
    "    'gyr_x',\n",
    "    'gyr_y',\n",
    "    'gyr_z',\n",
    "    'participant',\n",
    "    'label',\n",
    "    'category',\n",
    "    'set'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** There are bound to be rows filled with NaN values. That is because after merging the 2 data frames we will be dealing with 2 types of measurement and the chance that the accelerometer data is exactly the same as Gyroscope data while the device is in active status is fairly small.\n",
    "\n",
    "1. Accelerometer data\n",
    "2. Gyroscope data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be handling the null values through resampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "      <th>gyr_z</th>\n",
       "      <th>participant</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:04.950</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.671</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>5.976</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:04.990</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.720</td>\n",
       "      <td>-2.073</td>\n",
       "      <td>3.171</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.030</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488</td>\n",
       "      <td>-3.537</td>\n",
       "      <td>-4.146</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.070</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-5.854</td>\n",
       "      <td>3.537</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-2.805</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc_x  acc_y  acc_z   gyr_x  gyr_y  gyr_z  \\\n",
       "epoch (ms)                                                           \n",
       "2019-01-11 15:08:04.950    NaN    NaN    NaN -10.671 -1.524  5.976   \n",
       "2019-01-11 15:08:04.990    NaN    NaN    NaN  -8.720 -2.073  3.171   \n",
       "2019-01-11 15:08:05.030    NaN    NaN    NaN   0.488 -3.537 -4.146   \n",
       "2019-01-11 15:08:05.070    NaN    NaN    NaN   0.244 -5.854  3.537   \n",
       "2019-01-11 15:08:05.110    NaN    NaN    NaN  -0.915  0.061 -2.805   \n",
       "\n",
       "                        participant  label category   set  \n",
       "epoch (ms)                                                 \n",
       "2019-01-11 15:08:04.950           B  bench    heavy  64.0  \n",
       "2019-01-11 15:08:04.990           B  bench    heavy  64.0  \n",
       "2019-01-11 15:08:05.030           B  bench    heavy  64.0  \n",
       "2019-01-11 15:08:05.070           B  bench    heavy  64.0  \n",
       "2019-01-11 15:08:05.110           B  bench    heavy  64.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resampling:** When you convert a certain frequency to higher or lower range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will be resampling the data\n",
    "sampling = {\n",
    "    'acc_x': 'mean',\n",
    "    'acc_y': 'mean',\n",
    "    'acc_z': 'mean',\n",
    "    'gyr_x': 'mean',\n",
    "    'gyr_y': 'mean',\n",
    "    'gyr_z': 'mean',\n",
    "    'participant': 'last',\n",
    "    'label': 'last',\n",
    "    'category': 'last',\n",
    "    'set': 'last',  \n",
    "}\n",
    "\n",
    "\n",
    "days = [g for n, g in merged_data.groupby(pd.Grouper(freq='D'))]\n",
    "data_final = pd.concat([df.resample(rule='200ms').apply(sampling).dropna() for df in days])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing set from float to int\n",
    "data_final['set'] = data_final['set'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9009 entries, 2019-01-11 15:08:05.200000 to 2019-01-20 17:33:27.800000\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   acc_x        9009 non-null   float64\n",
      " 1   acc_y        9009 non-null   float64\n",
      " 2   acc_z        9009 non-null   float64\n",
      " 3   gyr_x        9009 non-null   float64\n",
      " 4   gyr_y        9009 non-null   float64\n",
      " 5   gyr_z        9009 non-null   float64\n",
      " 6   participant  9009 non-null   object \n",
      " 7   label        9009 non-null   object \n",
      " 8   category     9009 non-null   object \n",
      " 9   set          9009 non-null   int64  \n",
      "dtypes: float64(6), int64(1), object(3)\n",
      "memory usage: 774.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the dataset using the pickle method\n",
    "# Exporting as pickle over csv since it easier to work with timestamps there\n",
    "\n",
    "data_final.to_pickle('../data/interim/processed_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exercise-tracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
